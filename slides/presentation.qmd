---
title: "Pollution en Occitanie"
author: "Khadidiatou Kenewy DIALLO, Mario LAPI, Jeanne MANNEQUIN, Camille MOTTIER"
format: 
    revealjs:
        theme: sky
---

## Introduction

- **Le problème initial :**

Construction d'un site de visualisation des données récentes de pollution en Occitanie.

Données issues de : [Atmo Occitanie](https://data-atmo-occitanie.opendata.arcgis.com/pages/liste-des-flux)

&nbsp;

- **Les outils :**

  - Python
  - Quarto


## Les grands axes de réflexion

&nbsp;


Problématique : Comment rendre visible ...


- les dissimilarités géographiques --> Jeanne
- les dissimilarités temporelles --> Mario et Camille
- le lien avec la météo --> Kenewy


## Visualisation géographique 

Création d'une carte pour comparer les principales villes d'Occitanie

Le code : 

```{.python}
import folium
import pandas as pd
import math
import csv

# Créer une carte focus sur la région
m = folium.Map(location=[43.6000,1.4400], zoom_start=8,tiles='CartoDB Positron', attr='CartoDB Positron')

# Découper la carte en départements 
geojson_url = 'https://france-geojson.gregoiredavid.fr/repo/regions/occitanie/departements-occitanie.geojson'
folium.GeoJson(geojson_url, name='occitanie').add_to(m)

# Nom du fichier CSV
nom_fichier_csv = 'Mesure_annuelle_Region_Occitanie_Polluants_Principaux.csv'

# Ouvrir le fichier CSV en mode lecture
with open(nom_fichier_csv, newline='') as fichier_csv:
    lecteur_csv = csv.reader(fichier_csv)
    l=[]
    data2=[]
    # Lire les lignes du fichier CSV
    for ligne in lecteur_csv:
        if ligne[3] not in l:
            l.append(ligne[3])
        data2.append(ligne)
# Regrouper les données de façon à les utiliser (une station par ville qui est la moyenne des autres stations sur la même ville)
data=[]
liste=[]
p=0
for ville in l[1:]:
    s=0
    n=0
    for ligne in data2:
        if ligne[3] == ville:
            s+=float(ligne[11])
            n+=1
            if ligne[3] not in liste:
                data.append(ligne)
            liste.append(ville)
    s=s/n
    data[p][11]=s
    p+=1
# Créer un data utilisable par folium
lat=[]
lon=[]
name=[]
value=[]     
for ligne in data:
    lat.append(float(ligne[1]))
    lon.append(float(ligne[0]))
    name.append(ligne[3])
    value.append(float(ligne[11]))
data3 = pd.DataFrame({
   'lat':lat,
   'lon':lon,
   'name':name,
   'value':value
})

#Création de cercles proportionnels à la mesure de pm10 présent par ville
for city in data3.itertuples():
    local_deformation = math.cos(city.lat * math.pi / 180)
    folium.Circle(
        location=[city.lat, city.lon],
        popup=folium.Popup(f"{city.value} µm/m³"),
        tooltip=folium.Tooltip(city.name),
        radius=city.value * 800.0 * local_deformation, #le facteur 800 est choisit arbitrairement
        color='purple',
        fill=True,
        fill_color='purple'
    ).add_to(m)

# Montrer la carte
m
```



## Évolution temporelle : la nécessaire création de modules

Comment adapter aux différentes villes le code dans quarto ?


```{.python}
from Month import *
from Horloge import * 
from Month_resume import *
from Tracegraph import *

data = pd.read_csv("Mesure_horaire_(30j)_Region_Occitanie_Polluants_Reglementaires.csv")

station = 'Montpellier - Prés d Arènes Urbain'

Trace_go(data,station,'Montpellier')

trace_resume(data, station)

Horloge_semaine(data, station)

Horloge_weekend(data,station)


url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/mesures_occitanie_mensuelle_poll_princ/FeatureServer/0/query?f=json&where=(nom_com%20IN%20('MONTPELLIER'))&outFields=*"
selected_attributes = ['nom_com', 'nom_poll', 'valeur', 'date_debut']
cityname = 'MONTPELLIER'

tracegraph(url, selected_attributes,cityname)
```

## Évolution temporelle : les tracés

Modules prédéfinis utilisés : pandas, plotly

Modules créés : Month, Month_resume, Horloge, Tracegraph

```{.python}
import pandas as pd
import plotly.graph_objects as go
from Month import *

#%%

"""
Module permettant la construction du graphe donnant les valeurs moyennes, minimales et maximales sur un mois
L'extraction des données se fait grâce au module Month
"""

# resume crée un dataframe avec les valeurs des minimums, maximums et moyennes par jour

def resume(data, station):
    df = extraction(data, station)
    df = df.set_index(["Date"])
    df["jour"] = df.index.date
    df.rename(columns={"nom_poll": "Polluants"}, inplace=True)
    df_moy = (
        df.groupby(["Polluants", "jour"]).agg(min = ("valeur", min), max = ("valeur", max), moyenne = ("valeur", 'mean'))
        .reset_index()
    )
    return df_moy

# hex_rgba gère la transparence des couleurs

def hex_rgba(hex, transparency):
    col_hex = hex.lstrip('#')
    col_rgb = list(int(col_hex[i:i+2], 16) for i in (0, 2, 4))
    col_rgb.extend([transparency])
    areacol = tuple(col_rgb)
    return areacol

# trace_resume donne un graphe avec les valeurs minimales, maximales, moyennes ainsi que le seuil de référence

def trace_resume(data, station) :
    df = resume(data, station)
    fig = go.Figure()
    colors = px.colors.qualitative.Plotly
    rgba = [hex_rgba(c, transparency=0.2) for c in colors]
    c =0
    for i in df["Polluants"].unique() : 
        c +=1
        new_col = colors[c]
        col_fond = rgba[c]
        df_poll = df[(df.Polluants == i)]
        x = df_poll["jour"]
        fig.add_traces(go.Scatter(
            x = x,
            y = df_poll["moyenne"],
            mode = 'lines',
            name = i,
            legendgroup = i,
            line = dict(color=new_col, width=2.5)
        )
        )
        fig.add_traces(go.Scatter(
            name = 'Upper Bound',
            x = x,
            y = df_poll["max"],
            legendgroup = i,
            showlegend=False,
            line=dict(width=0)
        )
        )
        fig.add_traces(go.Scatter(
            name = 'Lower Bound',
            x = x,
            y = df_poll["min"],
            fill = 'tonexty',
            legendgroup = i,
            showlegend=False,
            line=dict(width=0),
            fillcolor= 'rgba'+str(col_fond),
        )
        )
        if i == 'PM2.5' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [5]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
        if i == 'PM10' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [15]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
        if i == 'O3' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [60]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
        if i == 'NO2' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [10]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
    fig.update_layout(
        width=1000,
        height=550,
        xaxis_title="Date",
        yaxis_title="Concentration (µg/m³)",
        title_text = "Concentrations minimale, maximale, moyenne journalières et seuils de référence (OMS)"
    )
    fig.show()
```

## Import des données

D'un csv en local à une requête en ligne...

```{.python}
import requests
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go

def tracegraph(url, selected_attributes, city_name):
    # Fonction pour récupérer les données de pollution
    def get_pollution_data(url, selected_attributes, city_name):
        response = requests.get(url)
        
        if response.status_code == 200:
            data = response.json()
            features = data.get('features', [])
            
            if not features:
                print(f"Aucune donnée trouvée pour {city_name}")
                return None
            
            city_data = []
            for feature in features:
                if 'attributes' in feature:
                    properties = feature['attributes']
                    if properties.get('nom_com') == city_name:
                        entry = {key: properties.get(key, None) for key in selected_attributes}
                        if entry.get('valeur') is not None:
                            entry['date_debut'] = pd.to_datetime(entry['date_debut'], unit='ms')
                            city_data.append(entry)
            
            if not city_data:
                print(f"Aucune donnée trouvée pour {city_name}")
                return None
            
            df = pd.DataFrame(city_data, columns=selected_attributes)
            return df
        else:
            print(f"Erreur de requête avec le code {response.status_code}")
            return None
    
    # Appel de la fonction pour récupérer les données
    city_data_frame = get_pollution_data(url, selected_attributes, city_name)

    if city_data_frame is None:
        return  # Sortir si aucune donnée n'est récupérée

    # Convertir la colonne 'valeur' en un type numérique
    city_data_frame['valeur'] = pd.to_numeric(city_data_frame['valeur'], errors='coerce')

    # Grouper par mois et par polluant, calculer la moyenne
    average_data = city_data_frame.groupby(['nom_poll', city_data_frame['date_debut'].dt.to_period("M")])['valeur'].mean().reset_index()

    # Créer une figure interactive Plotly
    fig = go.Figure()

    # Tracer des courbes pour chaque polluant
    for pollutant in average_data['nom_poll'].unique():
        data = average_data[average_data['nom_poll'] == pollutant]
        fig.add_trace(go.Scatter(x=data['date_debut'].dt.to_timestamp(), y=data['valeur'], mode='lines+markers', name=pollutant))

    # Configurer la mise en page interactive
    fig.update_layout(title=f'Moyenne de concentration des polluants à {city_name} par mois ',
                      xaxis_title='Date',
                      yaxis_title='Moyenne de Concentration en μg/m3',
                      xaxis=dict(type='date'),
                      xaxis_rangeslider_visible=True)

    # Afficher la figure interactive
    fig.show()
```

## La mise en relation avec les données météorologiques

## Le déploiement


&nbsp;


- Utilisation d'une action github

- Emploi du workflow Quarto Publish, afin d'automatiser le déploiement à chaque nouvelle contribution.

- [Le rendu](https://cmottier.github.io/PROJET-Pollution_en_Occitanie/)



## Pour conclure ...{.smaller}


- **Intérêt du projet**

    Les découvertes...


&nbsp;

- **Le travail de groupe**

  - Github 
  - Réunions

&nbsp;

- **Améliorations**

  - Import automatisé
  - Étude des temps de calculs
  - Documentation



<!-- ## Évolution sur 30 jours

```{python}
#| echo: true
#| code-fold: true

# Extrait du quarto de Montpellier

from Month import *

data = pd.read_csv("Mesure_horaire_(30j)_Region_Occitanie_Polluants_Reglementaires.csv")

station = 'Montpellier - Prés d Arènes Urbain'

Trace_go(data,station,'Montpellier')
```




## Résumé des 30 jours{.smaller}

Module Month_resume

```{python}

#| echo: true
#| code-fold: true

import pandas as pd
import plotly.graph_objects as go
from Month import *

#%%

"""
Module permettant la construction du graphe donnant les valeurs moyennes, minimales et maximales sur un mois
L'extraction des données se fait grâce au module Month
"""

# resume crée un dataframe avec les valeurs des minimums, maximums et moyennes par jour

def resume(data, station):
    df = extraction(data, station)
    df = df.set_index(["Date"])
    df["jour"] = df.index.date
    df.rename(columns={"nom_poll": "Polluants"}, inplace=True)
    df_moy = (
        df.groupby(["Polluants", "jour"]).agg(min = ("valeur", min), max = ("valeur", max), moyenne = ("valeur", 'mean'))
        .reset_index()
    )
    return df_moy

# hex_rgba gère la transparence des couleurs

def hex_rgba(hex, transparency):
    col_hex = hex.lstrip('#')
    col_rgb = list(int(col_hex[i:i+2], 16) for i in (0, 2, 4))
    col_rgb.extend([transparency])
    areacol = tuple(col_rgb)
    return areacol

# trace_resume donne un graphe avec les valeurs minimales, maximales, moyennes ainsi que le seuil de référence

def trace_resume(data, station) :
    df = resume(data, station)
    fig = go.Figure()
    colors = px.colors.qualitative.Plotly
    rgba = [hex_rgba(c, transparency=0.2) for c in colors]
    c =0
    for i in df["Polluants"].unique() : 
        c +=1
        new_col = colors[c]
        col_fond = rgba[c]
        df_poll = df[(df.Polluants == i)]
        x = df_poll["jour"]
        fig.add_traces(go.Scatter(
            x = x,
            y = df_poll["moyenne"],
            mode = 'lines',
            name = i,
            legendgroup = i,
            line = dict(color=new_col, width=2.5)
        )
        )
        fig.add_traces(go.Scatter(
            name = 'Upper Bound',
            x = x,
            y = df_poll["max"],
            legendgroup = i,
            showlegend=False,
            line=dict(width=0)
        )
        )
        fig.add_traces(go.Scatter(
            name = 'Lower Bound',
            x = x,
            y = df_poll["min"],
            fill = 'tonexty',
            legendgroup = i,
            showlegend=False,
            line=dict(width=0),
            fillcolor= 'rgba'+str(col_fond),
        )
        )
        if i == 'PM2.5' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [5]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
        if i == 'PM10' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [15]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
        if i == 'O3' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [60]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
        if i == 'NO2' :
            fig.add_traces(go.Scatter(
                line=dict(color=new_col, dash='dot'),
                x = x,
                y = [10]*len(x),
                # line_color = new_col,
                legendgroup = i,
                showlegend=False,
            ))
    fig.update_layout(
        width=1000,
        height=550,
        xaxis_title="Date",
        yaxis_title="Concentration (µg/m³)",
        title_text = "Concentrations minimale, maximale, moyenne journalières et seuils de référence (OMS)"
    )
    fig.show()
    
# Comandes extraites du fichier quarto :

data = pd.read_csv("Mesure_horaire_(30j)_Region_Occitanie_Polluants_Reglementaires.csv")

station = 'Montpellier - Prés d Arènes Urbain'

trace_resume(data, station)
```

## Dissimilarités horaires

Module Horloge

```{python}

#| echo: true
#| code-fold: true

import pandas as pd
import calendar
import plotly.express as px
import plotly.graph_objects as go
from Month import *

#%%
"""
Module permettant la construction des graphes en forme d'horloge permettant les comparaisons horaires
L'extraction des données se fait grâce au module Month
"""

# Semaine crée le dataframe pour l'affichage horaire en semaine (extraction des jours de semaine)

def semaine(data, station):
    df = extraction(data, station)
    df = df.set_index(["Date"])
    df["jour_semaine"] = df.index.day_of_week
    df_semaine = df.loc[(df["jour_semaine"] < 5 ), : ]
    df_semaine = df_semaine.drop('jour_semaine', axis = 1)
    return df_semaine

# Weekend crée le dataframe pour l'affichage horaire en weekend (extraction des jours du weekend)

def weekend(data, station):
    df = extraction(data, station)
    df = df.set_index(["Date"])
    df["jour_semaine"] = df.index.day_of_week
    df_weekend = df.loc[(df["jour_semaine"] >4 ), : ]
    df_weekend = df_weekend.drop('jour_semaine', axis = 1)
    return df_weekend

# Horloge trace la moyenne des données horaires en polar

def Horloge(df) :
    df.rename(columns={"nom_poll": "Polluants"}, inplace=True)
    df["heure"] = df.index.hour
    df_polar = (
        df.groupby(["Polluants","heure"])["valeur"]
        .mean()
        .reset_index()
    )
    df_polar = df_polar.astype({"heure": str}, copy=False)
    fig = px.line_polar(
        df_polar,
        r="valeur",
        theta="heure",
        color="Polluants",
    )
    return fig

# Horloge_semaine affiche le graphique pour les jours de semaine

def Horloge_semaine(data, station):
    fig = Horloge(semaine(data, station))
    fig.update_layout(title="Concentration moyenne horaire en semaine, au cours du dernier mois")
    fig.show()

# Horloge_weekend affiche le graphique pour les jours de weekend

def Horloge_weekend(data, station):
    fig = Horloge(weekend(data, station))
    fig.update_layout(title="Concentration moyenne horaire en weekend, au cours du dernier mois")
    fig.show()

```


:::: {.columns}

::: {.column width="50%"}
```{python}
from Month import *
from Horloge import * 

data = pd.read_csv("Mesure_horaire_(30j)_Region_Occitanie_Polluants_Reglementaires.csv")

station = 'Montpellier - Prés d Arènes Urbain'

Horloge_semaine(data, station)

```

:::

::: {.column width="50%"}
```{python}
from Month import *
from Horloge import * 

data = pd.read_csv("Mesure_horaire_(30j)_Region_Occitanie_Polluants_Reglementaires.csv")

station = 'Montpellier - Prés d Arènes Urbain'

Horloge_weekend(data,station)
```

:::

:::: -->

<!-- 
## Comparaison saisonnière{.smaller}


Objectifs: Comparer les différentes concentration de polluants 
et visualiser leur évolution sur une échelle de temps longue.

Module Tracegraph

```{.python}
import requests
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go

def tracegraph(url, selected_attributes, city_name):
    # Fonction pour récupérer les données de pollution
    def get_pollution_data(url, selected_attributes, city_name):
        response = requests.get(url)
        
        if response.status_code == 200:
            data = response.json()
            features = data.get('features', [])
            
            if not features:
                print(f"Aucune donnée trouvée pour {city_name}")
                return None
            
            city_data = []
            for feature in features:
                if 'attributes' in feature:
                    properties = feature['attributes']
                    if properties.get('nom_com') == city_name:
                        entry = {key: properties.get(key, None) for key in selected_attributes}
                        if entry.get('valeur') is not None:
                            entry['date_debut'] = pd.to_datetime(entry['date_debut'], unit='ms')
                            city_data.append(entry)
            
            if not city_data:
                print(f"Aucune donnée trouvée pour {city_name}")
                return None
            
            df = pd.DataFrame(city_data, columns=selected_attributes)
            return df
        else:
            print(f"Erreur de requête avec le code {response.status_code}")
            return None
    
    # Appel de la fonction pour récupérer les données
    city_data_frame = get_pollution_data(url, selected_attributes, city_name)

    if city_data_frame is None:
        return  # Sortir si aucune donnée n'est récupérée

    # Convertir la colonne 'valeur' en un type numérique
    city_data_frame['valeur'] = pd.to_numeric(city_data_frame['valeur'], errors='coerce')

    # Grouper par mois et par polluant, calculer la moyenne
    average_data = city_data_frame.groupby(['nom_poll', city_data_frame['date_debut'].dt.to_period("M")])['valeur'].mean().reset_index()

    # Créer une figure interactive Plotly
    fig = go.Figure()

    # Tracer des courbes pour chaque polluant
    for pollutant in average_data['nom_poll'].unique():
        data = average_data[average_data['nom_poll'] == pollutant]
        fig.add_trace(go.Scatter(x=data['date_debut'].dt.to_timestamp(), y=data['valeur'], mode='lines+markers', name=pollutant))

    # Configurer la mise en page interactive
    fig.update_layout(title=f'Moyenne de concentration des polluants à {city_name} par mois ',
                      xaxis_title='Date',
                      yaxis_title='Moyenne de Concentration en μg/m3',
                      xaxis=dict(type='date'),
                      xaxis_rangeslider_visible=True)

    # Afficher la figure interactive
    fig.show()
```

## Comparaison saisonnière

Rendu sur un exemple: Montpellier

```{python}

#| echo: true
#| code-fold: true



from Tracegraph import *


url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/mesures_occitanie_mensuelle_poll_princ/FeatureServer/0/query?f=json&where=(nom_com%20IN%20('MONTPELLIER'))&outFields=*"
selected_attributes = ['nom_com', 'nom_poll', 'valeur', 'date_debut']

cityname = 'MONTPELLIER'

tracegraph(url, selected_attributes,cityname)
```
 -->
